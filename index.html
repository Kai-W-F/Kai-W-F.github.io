<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Bias in AI</title>
</head>
<body>
    <section>
        <div class="circle"></div>
        <header>
            <a href="#" ><img src="media/logo.png" alt="AI" class="logo"></a> 

            <ul>
                <li><a href="#">Home</a></li>
                <li><a href="#">Works Cited</a></li>
                <li><a href="#">Contact</a></li>
            </ul>
        </header>
        <div class="content">
            <div class="text_box">
                <h2>Can we Trust <span>AI</span> to be Unbiased?</h2>
                <p>
                    AI has become an increasingly popular solution to automate all sorts of tasks around the world, but are we sure that we can trust these AIs to be objective and free from the biases 
                    a human could have? While it is common to view AI as above having human bias, they are not as fool-proof as it may seem. However, before I explain that, I need to define a few 
                    terms and what an AI is. To begin, there are two types of AI: 1) an AI where the developer writes out a strict set of rules and the program follows that, and 2) 
                    a machine learning AI that is given mass amounts of data to review, which they then create their own set of “rules” in the form of a mathematical probability model. 
                    In this paper I will strictly be talking about the latter, machine learning AI, due to it being by far the much more common as well as the much less certain outcomes 
                    it brings. Now that I have laid out what an AI is, it is important to understand what that entails: 1) the AI will always be “objective” in the sense that it will 
                    always give the “correct” output given the training data and model design; it does not think, 2) what the model thinks is right is not necessarily what is actually 
                    right, and 3) due to the nature of machine learning, the creators or developers of AI do not have much insight into what the AI is looking for in order to 
                    classify or predict something. The developers only know the input, output, training data, and the overall model design. Because of this, an AI can contain bias 
                    without the developers' knowing or directly adding it, which can be very problematic given that AI is making its way into fields with higher stakes such as healthcare 
                    or governmental services.
                </p>
                <p> 
                    Now, to address the question posed at the beginning, can trust AI to be free from bias in its decision making? While the literature review showed possible 
                    sources for bias, it did not assess whether or not developers for AI are being mindful enough of them and taking them into account enough that we can trust their
                    AI will be free of that bias. In the following paper (On this webpage for multimodal), I will explain how we cannot trust AIs to be free of human bias for the 
                    following reasons: 1) creators of AI often used flawed methodology and inadequate training data, 2) societal and embedded biases will inevitably appear in data 
                    used to train the AI, and 3) the current regulations and audits for AI fairness are inadequate. 
                </p>
                <a href="#">Literature Review</a>
            </div>
            <div class="img_box">
                <img src="media/home_image.png" alt="" class="home_background">
            </div>
        </div>
    </section>
</body>
</html>