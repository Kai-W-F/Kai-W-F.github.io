<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Bias in AI</title>
</head>
<body>
    <section>
        <div class="circle"></div>
        <header>
            <a href="index.html" ><img src="media/logo.png" alt="AI" class="logo"></a> 

            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="bibliography.html">Works Cited</a></li>
                <li><a href="author.html">Author</a></li>
            </ul>
        </header>
        <div class="content">
            <div class="text_box">
                <h2>Literature Review: Bias in <span>AI</span></h2>
                <p>
                    In the scholarly conversation about AI bias, the articles identify three general categories for sources of bias: 1) bias in training data, 2) 
                    flawed model design, and 3) lack of adequate checks for accuracy. In the case of the first cause, this can come in any training data is not an 
                    adequate representation of the population as mentioned by Akter et al (2021), Landers and Behrend (2022), and Michael et al (2022), or it can come 
                    in the form of pre-existing biases in society or the data recorded that become part of the AI like mentioned by Noor (2020), Cho (2021), and Nwafor (2021). 
                    As for flawed model design, Landers and Behrend (2022) and Akter et al (2021) both agree that a poor model design and methodology can undermine good 
                    training data. However, Noor (2020) and Nwafor (2021) take a different view pointing out how the bias of the creators will inevitably appear in the model. 
                    Lastly, all sources point out how better regulations/audits are needed to stop bias in AI with Nwafor (2021) pointing out the flaws with the existing regulations. 
                    Overall, the sources agree on those three sources for bias, however they give different perspectives on how impactful developer bias is.
                </p>
            </div>
            <div class="card_box">
                <a href="train.html">
                    <div class="card">
                        <div class="card_image"> <img src="media/training.jpeg" /></div>
                        <div class="card_title">
                        <p>Training Data</p>
                        </div>
                    </div>
                </a>
                <a href="bias.html">
                <div class="card">
                    <div class="card_image"> <img src="media/bias.jpeg" /></div>
                    <div class="card_title">
                      <p>Embedded Bias</p>
                    </div>
                </div>
                </a>
                <a href="regulation.html">
                <div class="card">
                    <div class="card_image"> <img src="media/law.jpeg" /></div>
                    <div class="card_title">
                      <p>Lack of Regulation</p>
                    </div>
                </div>
            </a>
        </div>
    </section>
</body>
</html>