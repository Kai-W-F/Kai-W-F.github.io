<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Bias in AI</title>
</head>
<body>
    <section>
        <div class="circle"></div>
        <header>
            <a href="index.html" ><img src="media/logo.png" alt="AI" class="logo"></a> 

            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="bibliography.html">Works Cited</a></li>
                <li><a href="author.html">Author</a></li>
            </ul>
        </header>
        <div class="content">
            <div class="text_box">
                <h2><span>Regulations</span> for Fairness in AI are Inadequate and Lacking</h2>
                <p>
                    We also cannot trust in AI to not contain human biases because there are few and inadequate regulations and standards for fairness in AI. 
                    One reason for the lack of standardization in AI is that it has only become an issue in recent years. However, Noor (2020) also notes, 
                    “bias and discrimination are such difficult things to regulate”. Noor also points out how AIs developed commercially have no incentive or standard 
                    to make a robust and reliable AI. Due to this, there are few and inadequate government regulations on AI fairness, and developers have less motive to 
                    worry about the potential biases because they have no standards to meet. One law that could apply to bias in AI is the GDPR(General Data Protection Regulation) 
                    in the EU. However, this regulation is designed for data privacy not discrimination in AI and thus falls short of being sufficient:  “Borgesius argues that data 
                    protection law is not enveloping enough to safeguard people against algorithm discrimination. He highlights the drawbacks of such laws to include compliance and 
                    enforcement and their applicability to personal data”(Nwafor, 2021). Due to the insufficient regulations, we cannot be sure that AIs do not contain human bias 
                    and are “fair”. 

                </p>
            </div>
            <div class="card_box">
                <a href="train.html">
                    <div class="card">
                        <div class="card_image"> <img src="media/training.jpeg" /></div>
                        <div class="card_title">
                        <p>Training Data</p>
                        </div>
                    </div>
                </a>
                <a href="bias.html">
                <div class="card">
                    <div class="card_image"> <img src="media/bias.jpeg" /></div>
                    <div class="card_title">
                      <p>Embedded Bias</p>
                    </div>
                </div>
                </a>
                <a href="regulation.html">
                <div class="card">
                    <div class="card_image"> <img src="media/law.jpeg" /></div>
                    <div class="card_title">
                      <p>Lack of Regulation</p>
                    </div>
                </div>
            </a>
        </div>
    </section>
</body>
</html>