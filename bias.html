<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Bias in AI</title>
</head>
<body>
    <section>
        <div class="circle"></div>
        <header>
            <a href="index.html" ><img src="media/logo.png" alt="AI" class="logo"></a> 

            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="bibliography.html">Works Cited</a></li>
                <li><a href="author.html">Author</a></li>
            </ul>
        </header>
        <div class="content">
            <div class="text_box">
                <h2><span>Embedded Biases</span> often make their way into AI</h2>
                <p>
                    AI cannot be free of some human bias due to how it embeds societal biases into the model. Because AIs are designed to replicate or mimic what occurs in their training datasets, 
                    if that historical data is taken from observing a system with embedded bias or societal bias, the AI will learn that bias. In other words, if you train the AI to mimic something 
                    in a society with embedded systematic bias, the AI will further embed that bias into future data and technology. This can end up even increasing discrimination towards 
                    disadvantaged groups: “Social and historical biases embedded within the dataset can exaggerate harm to disadvantaged populations of different social status, religion, 
                    sexual orientation, subcultures, age groups, gender and other social groups”(Akter et al, 2021). Thus in order to exclude this bias, either the population needs to lose this 
                    bias (though historical data could still contain it) or the training data needs to be extensively audited for these biases. When most of these AI are being created for 
                    commercial use, it is unreasonable to expect creators of AI to extensively audit mass amounts of data when no regulations require them to. Moreover, outside of societal biases, 
                    it can also embed common embedded biases in certain fields or practices. The most famous example of this is Amazon's recruitment AI, in which the AI rejected all women due to 
                    a few women being in the field and the AI learning that bias (Dastin 2018). 
                    In all, it is difficult to prevent societal bias appearing in AI and thus AI will further embed present or historical systematic bias.
                </p>
            </div>
            <div class="card_box">
                <a href="train.html">
                    <div class="card">
                        <div class="card_image"> <img src="media/training.jpeg" /></div>
                        <div class="card_title">
                        <p>Training Data</p>
                        </div>
                    </div>
                </a>
                <a href="bias.html">
                <div class="card">
                    <div class="card_image"> <img src="media/bias.jpeg" /></div>
                    <div class="card_title">
                      <p>Embedded Bias</p>
                    </div>
                </div>
                </a>
                <a href="regulation.html">
                <div class="card">
                    <div class="card_image"> <img src="media/law.jpeg" /></div>
                    <div class="card_title">
                      <p>Lack of Regulation</p>
                    </div>
                </div>
            </a>
        </div>
    </section>
</body>
</html>